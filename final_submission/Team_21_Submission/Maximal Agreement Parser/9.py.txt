#!/usr/bin/env python
import tika
from tika import language
import cbor
import os
import json
import re
import httplib
import urllib
import unicodedata
from tika import parser

tika.initVM()

path = "/home/vinds/Kukku/sorteddata/crawl/test"

def get_filepaths(directory):
    json_file = open("run10.json", "w")
    connToNLTK = httplib.HTTPConnection('localhost:8881')
    finaloutput = {}
    cleanText = "null"
    for root, directories, files in os.walk(directory):
        for filename in files:
	    print filename
	    metaJSON = {}
            filepath = os.path.join(root, filename)
	    #------------------Tika MetaData and Content--------
	    try:
	        parsed = parser.from_file(filepath)
    	        metadata = parsed["metadata"]
    	        content = parsed["content"]
	    except:
		continue

	    #------------------NLTK Data------------------------
	    if len(content) is not 0:
	        contentToNLTK = content.replace( u'\u201d', u"'")
     	        contentToNLTK = contentToNLTK.replace( u'\u2019', u"'")
	        contentToNLTK = contentToNLTK.replace( u'\u201c', u'"')
    	        contentToNLTK = contentToNLTK.replace( u'\u2018', u'"')
#	        contentToNLTK = re.sub(r"\s+", " ",contentToNLTK)
	        contentToNLTK = re.sub('[^0-9a-zA-Z]+', ' ', contentToNLTK)
       	        contentToNLTK.encode('ascii','ignore')
		cleanText = contentToNLTK
	        connToNLTK.request('POST', '/nltk', contentToNLTK)
                response = connToNLTK.getresponse()
                output = response.read()
		if 'NOT_FOUND' not in output:
                    tmp = json.loads(output)
	            metaJSON["NLTKmetadata"] = tmp["names"]
		else:
 		    metaJSON["NLTKmetadata"] = " "
	        #print metaJSON["NLTKmetadata"]
	    else:
		metaJSON["NLTKmetadata"] = " "
	
	    #------------------CoreNLP Data---------------------
	    bashCommand = "java -Dner.impl.class=org.apache.tika.parser.ner.corenlp.CoreNLPNERecogniser -classpath $TIKA_APP:$CORE_NLP_JAR org.apache.tika.cli.TikaCLI --config=tika-config.xml -m "
	    output = os.popen(bashCommand+filepath).read()
	    results = output.split('\n')
	    orgString = ""
	    locString = ""
	    timeString = ""
	    percntString = ""
	    personString = ""
	    dateString = ""
	    prcntString = ""
	    moneyString = ""
	    parserString = ""
	    coreNLPdata = {}
  	    for result in results:
	    	if 'NER_ORGANIZATION' in result:
		    orgString+=result[18:]+","
    	        if 'NER_LOCATION' in result:
		    locString+=result[14:]+","
	        if 'NER_TIME' in result:
		    timeString+=result[10:]+","
	        if 'NER_PERSON' in result:
		    personString+=result[12:]+","
	        if 'NER_DATE' in result:
		    dateString+=result[10:]+","
	        if 'NER_PERCENT' in result:
		    prcntString+=result[13:]+","
	        if 'NER_MONEY' in result:
		    moneyString+=result[11:]+","
	        if 'Parsed-By' in result:
	  	    parserString+=result[13:]+","
		    if isinstance(metaJSON["parsers"],list):
  		        metaJSON["parsers"].append(result[13:])
	    coreNLPdata["NER_LOCATION"]=locString[:-1].split(",")
	    coreNLPdata["NER_ORGANIZATION"]=orgString[:-1].split(",")
	    coreNLPdata["NER_TIME"]=timeString[:-1].split(",")
	    coreNLPdata["NER_PERCENT"]=prcntString[:-1].split(",")
	    coreNLPdata["NER_PERSON"]=personString[:-1].split(",")
	    coreNLPdata["NER_DATE"]=dateString[:-1].split(",")
	    coreNLPdata["NER_MONEY"]=moneyString[:-1].split(",")
	    coreNLPdata["PARSED_BY"]=parserString[:-1].split(",")
	    metaJSON["coreNLPdata"] = coreNLPdata
	    #------------------OpenNLP Data----------------------
	    bashCommand = 'java -classpath $NER_RES:$TIKA_APP org.apache.tika.cli.TikaCLI --config=tika-config.xml -m '
	    output = os.popen(bashCommand+filepath).read()
	    results = output.split('\n')
	    orgString = ""
	    locString = ""
	    timeString = ""
	    percntString = ""
	    personString = ""
	    dateString = ""
	    prcntString = ""
	    moneyString = ""
	    parserString = ""
	    openNLPdata = {}
  	    for result in results:
	    	if 'NER_ORGANIZATION' in result:
		    orgString+=result[18:]+","
    	        if 'NER_LOCATION' in result:
		    locString+=result[14:]+","
	        if 'NER_TIME' in result:
		    timeString+=result[10:]+","
	        if 'NER_PERSON' in result:
		    personString+=result[12:]+","
	        if 'NER_DATE' in result:
		    dateString+=result[10:]+","
	        if 'NER_PERCENT' in result:
		    prcntString+=result[13:]+","
	        if 'NER_MONEY' in result:
		    moneyString+=result[11:]+","
	        if 'Parsed-By' in result:
	  	    parserString+=result[13:]+","
		    if isinstance(metaJSON["parsers"],list):
		        if result[13:] not in metaJSON["parsers"]:
		            metaJSON["parsers"].append(result[13:])
	    openNLPdata["NER_LOCATION"]=locString[:-1].split(",")
	    openNLPdata["NER_ORGANIZATION"]=orgString[:-1].split(",")
	    openNLPdata["NER_TIME"]=timeString[:-1].split(",")
	    openNLPdata["NER_PERCENT"]=prcntString[:-1].split(",")
	    openNLPdata["NER_PERSON"]=personString[:-1].split(",")
	    openNLPdata["NER_DATE"]=dateString[:-1].split(",")
	    openNLPdata["NER_MONEY"]=moneyString[:-1].split(",")
	    openNLPdata["PARSED_BY"]=parserString[:-1].split(",")
	    metaJSON["openNLPdata"] = openNLPdata
	    #------------------Grobid Quantities-------------------
	    data ={}
	    data['measurements'] = {}
	    if len(content) is not 0:
		print len(content)
		re.sub(r"\s+", " ",content)
	        input_text = re.sub('[^0-9a-zA-Z]+', ' ', content)
	        connToNLTK = httplib.HTTPConnection('localhost:8080')
	        params = urllib.urlencode({'text': input_text})
	        headers = {'Accept': 'application/json'}
	        connToNLTK.request('POST', '/processQuantityText', params, headers)
	        response = connToNLTK.getresponse()
                out = response.read()
	        data = json.loads(out)
	    jsonData = {}
	    tempString = ''
	    measureString = ''
	    massString = ''
	    otherString = ''
	    timeString = ''
	    for measurement in data['measurements']:
		if 'quantity' in measurement and 'quantityLeast' not in measurement:
		    if 'type' in measurement['quantity'] and 'rawUnit' in measurement['quantity']:
			if 'temperature' in measurement['quantity']['type']:
			    #print measurement['quantity']['rawValue']+" "+measurement['quantity']['rawUnit']['name']
			    tempString+=measurement['quantity']['rawValue']+" "+measurement['quantity']['rawUnit']['name']+","
			if 'length' in measurement['quantity']['type']:
			    #print measurement['quantity']['rawValue']+" "+measurement['quantity']['rawUnit']['name']
			    measureString+=measurement['quantity']['rawValue']+" "+measurement['quantity']['rawUnit']['name']+","
			if 'mass' in measurement['quantity']['type']:
			    #print measurement['quantity']['rawValue']+" "+measurement['quantity']['rawUnit']['name']
			    massString+=measurement['quantity']['rawValue']+" "+measurement['quantity']['rawUnit']['name']+","
			if 'time' in measurement['quantity']['type']:
			    #print measurement['quantity']['rawValue']+" "+measurement['quantity']['rawUnit']['name']
			    timeString+=measurement['quantity']['rawValue']+" "+measurement['quantity']['rawUnit']['name']+","
		    else:
			#print "Others "+measurement['quantity']['rawValue']+" "+measurement['quantity']['rawUnit']['name']
			if 'rawUnit' in measurement['quantity']:
  			    otherString+=measurement['quantity']['rawValue']+" "+measurement['quantity']['rawUnit']['name']+","
			else:
			    otherString+=measurement['quantity']['rawValue']+","
	    	jsonData["temperature"] = tempString[:-1].split(",")
	    	jsonData["measurement"] = measureString[:-1].split(",")
	    	jsonData["mass"] = massString[:-1].split(",")
	    	jsonData["time"] = timeString[:-1].split(",")
	    	jsonData["other"] = otherString[:-1].split(",")
	    	metaJSON["grobidQty"] = jsonData		
	    finaloutput[filename] = metaJSON
    json.dump(finaloutput, json_file, indent=2)    	  
    json_file.close()
    connToNLTK.close()
get_filepaths(path)
